
django -r 7960 kullanıyoruz


############################################################################
operasyonlar hep urller üzerind eyapılacak, o yüzden yapıyı buna göre kurmak
gerekiyor.


yapılandırma şeması:

       plugins
       options

Plugins: çeşitli pluginler ve bunların parametreleri. Pluginler sistemde varolan 
plugins dizininin taranması sonucunda ortaya çıkacak, ayarlama kısmı pluginlerin 
yapısına göre belirlenecek. Böylece web ui kısmında otomatizasyon sağlanacak. umarım.


Options: 
        profile name: profilin kaydedileceği isim
        seeds: başlangıç urlleri, urller aynı domainde olmayabilirler, buna göre de düşünmek lazım 
        max_concurrent_connections: aynı anda yapıalcak bağlantı sayısı.
        data encoding: urlin kendisinden alınacak, saklama utf-8 olarak yapılacak, sunumda gene 
        encoding ne ise ona göre olacak
        sleeper: karşı trafı yormamak için bağlantılar arası beklenecek süre
        user agent: string
        cookies: False/True
        connectiontimeout: bağlantı kurulması için max süre
        timeout: bağlantı kurulmuş, data çekiliyor, bunun için süre
        proxy: url:port type  *SONRA*
        autoreferer: referer auto olarak set made
        accept_encoding: zlib olabilir, gzip
        200aliases: gerekli mi bilemiyorum
        

############################################################################
rev 304:

  - crawler tam olarak çalışıyor.
  - remote job ve ui'den fork edilebility konusunu halletmek lazım 
  - interfacelei zenginleştirmek lazım 
  - pluginleri zenginleştirmek lazım



#############################################################################
profil yaratabilmek için modülleri gezip enabled disabled mevzuuna bakabilecek 
ve default seçenekleri de toparlayıp gösterebilmke lazım.

sonrasında bunları form olarak oluşturup göstermek lazım. formun yapısı da modüllerin 
durumuna göre olması lazım

dbyi berkeleydb falan yapmak iyi olabilir. en azından sql mevzularından kurtuluruz. 
bdb unicode konusunda problem çıkartıyor mu bakmak lazım. 


################################################################################
uiyi yaptıktan sonra birşey kalmıyor pek




http://simile.mit.edu/wiki/Solvent - Screen scraper - visual I think (open source)
http://simile.mit.edu/wiki/Piggy_Bank - Firefox plug-in. Looks interesting
http://grid.orch8.net/extractions/grab - visual building tool. Looks good (commercial)
http://viral.media.mit.edu/peers/doc/info.html - P2P toolkit for python. Maybe useful for distributed nature of crawler
http://www.cs.pitt.edu/mpqa/opinionfinderrelease/ - OpinionFinder. Might be interesting for looking at positive and negative meaning in an article
http://www.ailab.si/orange/ - component-based data mining software
http://www.elegantchaos.com/node/129 - Classifier for CRM114 (in python)
http://news.ycombinator.com/item?id=124085 - thread about classification. Looks similar to what wE are talking about and discusses CRM114 also


# class methodsu anlamak lazım
